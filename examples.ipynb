{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1173893c4f0ea56",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# late chunking chinese "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f93b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 使用huggingface镜像\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1380abf7acde9517",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('../late_chunking/jina-v2-zh', trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained('../late_chunking/jina-v2-zh', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef392f3437ef82e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_text: 战士金的新书已经出版了。他的新书名字是大模型RAG实战。这本书由机械工业出版社出版。可以在京东上购买。\n",
      "Chunks:\n",
      "- \"战士金的新书已经出版了。\"\n",
      "- \"他的新书名字是大模型RAG实战。\"\n",
      "- \"这本书由机械工业出版社出版。\"\n",
      "- \"可以在京东上购买。\"\n",
      "[(1, 7), (7, 16), (16, 22), (22, 27)]\n"
     ]
    }
   ],
   "source": [
    "input_text = \"战士金的新书已经出版了。他的新书名字是大模型RAG实战。这本书由机械工业出版社出版。可以在京东上购买。\"\n",
    "\n",
    "def chunk_by_sentences(input_text: str, tokenizer: callable,  split_token = \"。\"):\n",
    "    \"\"\"文本切块+找到每个文本块在token粒度的索引范围\"\"\"\n",
    "    print(\"input_text:\", input_text)\n",
    "    inputs = tokenizer(input_text, return_tensors='pt', return_offsets_mapping=True)\n",
    "    punctuation_mark_id = tokenizer.convert_tokens_to_ids(split_token)\n",
    "    token_offsets = inputs['offset_mapping'][0]\n",
    "    # 保证最后的句子保存起来\n",
    "    sep_id = int(token_offsets[-1][0])\n",
    "    token_ids = inputs['input_ids'][0]\n",
    "    # 找到文本粒度的划分\n",
    "    chunk_positions = []\n",
    "    for i, (token_id, (start, end)) in enumerate(zip(token_ids, token_offsets)):\n",
    "        if token_id == punctuation_mark_id:\n",
    "            if token_offsets[i + 1][0] - token_offsets[i][1] >= 0 or token_offsets[i + 1][0]==sep_id:\n",
    "                chunk_positions.append((i, int(start + 1))) \n",
    "    chunks = [\n",
    "        input_text[x[1] : y[1]]\n",
    "        for x, y in zip([(1, 0)] + chunk_positions[:-1], chunk_positions)\n",
    "    ]\n",
    "    span_annotations = [\n",
    "        (x[0], y[0]) for (x, y) in zip([(1, 0)] + chunk_positions[:-1], chunk_positions)\n",
    "    ]\n",
    "    return chunks, span_annotations\n",
    "\n",
    "\n",
    "split_token = \"。\"\n",
    "chunks, span_annotations = chunk_by_sentences(input_text, tokenizer, split_token=split_token) \n",
    "print('Chunks:\\n- \"' + '\"\\n- \"'.join(chunks) + '\"')\n",
    "print(span_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe3d93b9e6609b9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 传统chunk方法\n",
    "embeddings_traditional_chunking = model.encode(chunks)\n",
    "\n",
    "\n",
    "def chunked_pooling(\n",
    "    model_output, span_annotation: list, max_length=None\n",
    "):\n",
    "    \"\"\"对token embedding序列分chunk做mean pooling\"\"\"\n",
    "    token_embeddings = model_output[0]\n",
    "    outputs = []\n",
    "    for embeddings, annotations in zip(token_embeddings, span_annotation):\n",
    "        if (\n",
    "            max_length is not None\n",
    "        ):  # remove annotations which go bejond the max-length of the model\n",
    "            annotations = [\n",
    "                (start, min(end, max_length - 1))\n",
    "                for (start, end) in annotations\n",
    "                if start < (max_length - 1)\n",
    "            ]\n",
    "        pooled_embeddings = [\n",
    "            embeddings[start:end].sum(dim=0) / (end - start)\n",
    "            for start, end in annotations\n",
    "            if (end - start) >= 1\n",
    "        ]\n",
    "        pooled_embeddings = [\n",
    "            embedding.detach().cpu().numpy() for embedding in pooled_embeddings\n",
    "        ]\n",
    "        outputs.append(pooled_embeddings)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "inputs = tokenizer(input_text, return_tensors='pt')\n",
    "model_output = model(**inputs)\n",
    "embeddings = chunked_pooling(model_output, [span_annotations])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0cec59a3ece76",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "native chunk score(\"战士金的新书叫什么\", \"战士金的新书已经出版了。\"): 0.838993\n",
      "late chunking score(\"战士金的新书叫什么\", \"战士金的新书已经出版了。\"): 0.9393679\n",
      "===\n",
      "native chunk score(\"战士金的新书叫什么\", \"他的新书名字是大模型RAG实战。\"): 0.7289395\n",
      "late chunking score(\"战士金的新书叫什么\", \"他的新书名字是大模型RAG实战。\"): 0.52649915\n",
      "===\n",
      "native chunk score(\"战士金的新书叫什么\", \"这本书由机械工业出版社出版。\"): 0.71318245\n",
      "late chunking score(\"战士金的新书叫什么\", \"这本书由机械工业出版社出版。\"): 0.3055911\n",
      "===\n",
      "native chunk score(\"战士金的新书叫什么\", \"可以在京东上购买。\"): 0.6868561\n",
      "late chunking score(\"战士金的新书叫什么\", \"可以在京东上购买。\"): 0.12445604\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cos_sim = lambda x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "query = '战士金的新书叫什么'\n",
    "berlin_embedding = model.encode(query)\n",
    "\n",
    "for chunk, new_embedding, trad_embeddings in zip(chunks, embeddings, embeddings_traditional_chunking):\n",
    "    print(f'late chunk score(\"{query}\", \"{chunk}\"):', cos_sim(berlin_embedding, new_embedding))\n",
    "    print(f'native chunking score(\"{query}\", \"{chunk}\"):', cos_sim(berlin_embedding, trad_embeddings))\n",
    "    print(\"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f430fde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
